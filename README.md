# Detec√ß√£o de √Åudios Falsos (DeepFake) com Estrat√©gias de Amplia√ß√£o e Balanceamento de Dados

## üìå Descri√ß√£o do Projeto

Este projeto investiga estrat√©gias de amplia√ß√£o e balanceamento de dados para melhorar a detec√ß√£o de √°udios verdadeiros e falsos (DeepFake).
O avan√ßo das tecnologias de s√≠ntese de voz tem tornado cada vez mais dif√≠cil diferenciar √°udios aut√™nticos de falsifica√ß√µes. Assim, o trabalho explora como diferentes t√©cnicas de **Data Augmentation** e **balanceamento de classes** influenciam o desempenho de modelos de aprendizado de m√°quina.

O objetivo principal √© avaliar quais combina√ß√µes de t√©cnicas ajudam os modelos a **generalizar melhor** para diferentes condi√ß√µes, mantendo a qualidade perceptiva e evitando distor√ß√µes excessivas.

## üìÇ Dados

### Origem

Os dados foram organizados em dois diret√≥rios principais:

* `real`: amostras de √°udios aut√™nticos
* `fake`: amostras geradas sinteticamente (DeepFake)

### Formato

* Arquivos `.wav` e `.mp3`
* Conjunto original balanceado entre as classes

## üéõ T√©cnicas de Amplia√ß√£o e Balanceamento

O projeto aplica **no m√°ximo uma t√©cnica de aumento por amostra**, limitando a expans√£o a **at√© o dobro do conjunto original**.

**Amplia√ß√£o de Dados (Data Augmentation)**

* **Adi√ß√£o de Ru√≠do**: adi√ß√£o de ru√≠do para simular diferentes condi√ß√µes de grava√ß√£o.
* **Varia√ß√£o de Velocidade**: acelera ou desacelera a taxa de reprodu√ß√£o, modificando as caracter√≠sticas temporais.
* **Varia√ß√£o de Tom**: simula varia√ß√µes vocais naturais sem comprometer a inteligibilidade.
* **Equaliza√ß√£o Aleat√≥ria**: aplica modifica√ß√µes no espectro de frequ√™ncias para representar diferentes equipamentos ou ambientes.
* **Mascaramento**: oculta regi√µes temporais ou frequenciais para simular perda parcial de informa√ß√£o.

**Balanceamento de Classes**

* **Random UnderSampling**: redu√ß√£o da classe majorit√°ria.
* **SMOTE**: gera√ß√£o sint√©tica de amostras minorit√°rias.

## ü§ñ Modelos Avaliados

* **Random Forest (RF)**
* **LightGBM (LGBM)**
* **Naive Bayes**
* **Long Short-Term Memory (LSTM)**
* **K-Nearest Neighbors (KNN)**

Todos os modelos foram treinados com **valida√ß√£o cruzada** (80% treino, 20% teste), usando **par√¢metros padr√£o** para isolar o efeito das t√©cnicas de amplia√ß√£o e balanceamento.

## üìè M√©tricas de Avalia√ß√£o

* **Acur√°cia**
* **Precis√£o**
* **Recall**
* **F1-Score**
* **Desvio Padr√£o** (para avaliar estabilidade entre execu√ß√µes)
## üì¨ Contato

Para d√∫vidas ou sugest√µes: **[vitormunnizz@gmail.com](mailto:vitormunnizz@gmail.com)**
